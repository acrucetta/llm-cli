Features
- [X] Add loading spinner while the LLM is thinking
- [x] Remove "ask" in favor of just calling "llm" with the question 
- [] Add ability to pass multiple files with -f e.g., -f file1.c file2.c "prompt"- [] Add the top-k most relevant results using embeddings for -d and use -c for codebase
- [] Add incremental typing to the output or a loading bar
- [] Add explanation modes that can be saved by the user with a tag e.g., -t "brainy" or --template
- [] Make the response faster
- [] Add a `repl` chat mode for follow-up responses
- [] Add a search capability for finding most relevant documents in an embedding
